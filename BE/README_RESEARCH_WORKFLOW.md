# Research Workflow - Quick Start Guide

## Overview

The research workflow provides intelligent query processing with:
- âœ… Query validation and refinement (Qwen3 LLM)
- âœ… Automatic query decomposition
- âœ… Parallel Tavily search
- âœ… LLM-powered result synthesis
- âœ… Human-in-the-loop for invalid queries
- âœ… Conversation persistence

## Prerequisites

1. **Ollama** with Qwen model:
   ```bash
   ollama pull qwen2.5:3b
   ```

2. **Tavily API Key** in `.env`:
   ```
   TAVILY_API_KEY=your_key_here
   ```

3. **Python dependencies**:
   ```bash
   pip install langgraph langchain-ollama langchain-core tavily-python
   ```

## Running the CLI

```bash
cd BE/src/finance_agent
python test_research_cli.py
```

## Example Usage

### Example 1: Valid Query
```
Enter your query: GiÃ¡ vÃ ng hÃ´m nay

Processing...
âœ“ Query validated
âœ“ Searching: "GiÃ¡ vÃ ng Viá»‡t Nam ngÃ y 04/02/2026"
âœ“ Report generated

RESEARCH COMPLETE
================================================================================
# BÃ¡o cÃ¡o GiÃ¡ VÃ ng

## TÃ³m táº¯t
...
```

### Example 2: Invalid Query (Human-in-Loop)
```
Enter your query: LÃ m bÃ¡nh pizza

Processing...
--------------------------------------------------------------------------------
ğŸ¤” Query khÃ´ng liÃªn quan Ä‘áº¿n tÃ i chÃ­nh. Vui lÃ²ng há»i vá» cá»• phiáº¿u, crypto, kinh táº¿, hoáº·c Ä‘áº§u tÆ°.

Vui lÃ²ng cung cáº¥p query liÃªn quan Ä‘áº¿n:
- Cá»• phiáº¿u, chá»©ng khoÃ¡n
- Tiá»n Ä‘iá»‡n tá»­ (crypto)
- TÃ i chÃ­nh, kinh táº¿, Ä‘áº§u tÆ°

(Láº§n há»i láº¡i: 1)
--------------------------------------------------------------------------------

Enter revised query: GiÃ¡ Bitcoin

Processing...
âœ“ Query validated
âœ“ Searching...
```

### Example 3: Complex Query (Decomposition)
```
Enter your query: So sÃ¡nh VNM vÃ  FPT

Processing...
âœ“ Query decomposed into 2 sub-queries
âœ“ Parallel search in progress...
  - "PhÃ¢n tÃ­ch cá»• phiáº¿u VNM 2026"
  - "PhÃ¢n tÃ­ch cá»• phiáº¿u FPT 2026"
âœ“ Synthesizing comparative report...

RESEARCH COMPLETE
================================================================================
# So sÃ¡nh VNM vÃ  FPT
...
```

## Architecture

```
User Query â†’ Orchestrator â†’ Reviewer (Qwen LLM)
                                â†“
                    Valid? â”€â”€Noâ†’ Ask User â†’ Loop
                      â†“ Yes
                    Search (Tavily, parallel)
                      â†“
                    Aggregator (Qwen LLM)
                      â†“
                    Memory (.txt file)
                      â†“
                    Final Report
```

## File Structure

```
BE/src/finance_agent/
â”œâ”€â”€ graph/
â”‚   â”œâ”€â”€ research_state.py          # State definitions
â”‚   â”œâ”€â”€ research_workflow.py       # Graph assembly
â”‚   â””â”€â”€ research_nodes/
â”‚       â”œâ”€â”€ orchestrator.py        # Entry point
â”‚       â”œâ”€â”€ reviewer.py            # LLM validation
â”‚       â”œâ”€â”€ search.py              # Tavily search
â”‚       â”œâ”€â”€ aggregator.py          # LLM synthesis
â”‚       â”œâ”€â”€ memory.py              # Persistence
â”‚       â””â”€â”€ ask_user.py            # Human-in-loop
â”œâ”€â”€ tools/
â”‚   â””â”€â”€ research.py                # TavilySearch tool
â””â”€â”€ test_research_cli.py           # CLI interface

conversations/                      # Saved conversations
â””â”€â”€ [uuid]_[timestamp].txt
```

## Conversation Files

Conversations are saved to `conversations/` directory:

```
================================================================================
FINTECH RESEARCH CONVERSATION
ID: abc-123-def
Timestamp: 2026-02-04T12:00:00
================================================================================

## CONVERSATION HISTORY

[HUMAN]: GiÃ¡ vÃ ng hÃ´m nay
[AI]: Query Ä‘Ã£ Ä‘Æ°á»£c refined...

================================================================================
## FINAL RESEARCH REPORT
================================================================================

[Full report content]

================================================================================
## METADATA
================================================================================
Original Query: GiÃ¡ vÃ ng hÃ´m nay
Iterations: 0
Sub-queries: 1
Search Results: 1
```

## Troubleshooting

### LLM Connection Error
```
Error: Failed to initialize LLM
```
**Fix:** Ensure Ollama is running and qwen2.5:3b is pulled:
```bash
ollama serve
ollama pull qwen2.5:3b
```

### Tavily API Error
```
Error: Tavily API call failed
```
**Fix:** Check your API key in `.env`:
```bash
echo $TAVILY_API_KEY  # Should print your key
```

### Import Errors
```
ModuleNotFoundError: No module named 'langgraph'
```
**Fix:** Install dependencies:
```bash
pip install -r requirements.txt
```

## Next Steps

- [ ] Test with various queries
- [ ] Monitor conversation files
- [ ] Review LLM prompts for accuracy
- [ ] Add Redis caching (future enhancement)
- [ ] Migrate memory to database

## Documentation

Full design documentation: `BE/docs/research_workflow_design.md`
